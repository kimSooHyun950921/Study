# 05-1 결정트리
- 결정트리: 예/아니오에대한 질문등으로 정답을 찾아 학습하는 알고리즘
- 불순도:
    - 지니계수: 한데이터에 얼마나 많은 클래스가 섞여있는지 판단하는 계수
        - 0이면 순수노드, 0.5이면 최악의 불순도
        - $$gini = 1 - \sum_{i}{C_i^2}$$
        - $$C_i^2 = 클래스 비율$$
    - 정보이득: 부모의 불순도와 자식의 불순도의차
        - 정보이득(info gain)이 큰 기준으로 나눔
        - $$Gain = gini_{parent} - \frac{N_{lchild}}{N_{parent}}*gini_{lchild} - \frac{N_{rchild}}{N_{parent}}*gini_{rchild}$$
    - 엔트로피로 지정하면 엔트로피 불순도를 사용할 수 있음 -(클래스비율*log(클래스비율))
- 특성값의 스케일은 결정트리의 알고리즘에 영향을 미치지 않음
    - scaler를 하지 않아도됨!
# 05-1 교차 검증과 그리드 서치
- 검증세트: 학습/검증/테스트를 60, 20, 20,으로 나눔
- 교차검증(cross validation)
    - 학습세트에서 검증/학습/테스트 세트를 무작위로 나누어 평가하는 방식
    - 만들어진 여러개의 검증세트로 모델 평가후 평균내는방식
- 하이퍼 파라미터 튜닝
    - 그리드 서치/랜덤 서치: 일반적으로 학습할때 다양한 하이퍼 파라미터 조합으로 학습을 시킨다. 하지만 파라미터 조합을 일일히 사람이 조정한다는것은 시간이 너무 많이 든다. 따라서, 이를 컴퓨터가 대신해서 조합해주는것 즉, scikit-learn은 하이퍼파라미터들의 범위를 정해주면 알아서 최고의 조합을 만들어준다.
    - GridSearch: parameter와 그 배열을 정해주면 알아셔 찾아줌
    - RandomSearch: parameter와 그 범위를 정해주면 랜덤으로 그 범위내 숫자들을 랜덤을 생성해서 최적의 하이퍼파라미터를 찾아줌